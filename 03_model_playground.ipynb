{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Playground\n",
    "\n",
    "This notebook is intended as a playground to test out different models. It allows you to load data, create a model and evaluate that model.\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "This code trains a convolutional neural network to perform obstacle detection. The model uses convolution and pooling layers, followed by a flattening layer and two fully connected layers, and outputs a binary classification result. The Adam optimizer and binary cross-entropy loss function are used to train the model, and its accuracy is evaluated on a testing set. The code also includes callbacks for model checkpoints and TensorBoard logging to monitor training progress. The model is significant because it can be used for various applications such as autonomous vehicles, surveillance systems, and robotics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 00:32:39.424746: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 40s 2s/step - loss: 41.6286 - accuracy: 0.6699 - val_loss: 0.5215 - val_accuracy: 0.8161\n",
      "Epoch 2/12\n",
      "17/17 [==============================] - 36s 2s/step - loss: 0.4687 - accuracy: 0.8301 - val_loss: 0.4124 - val_accuracy: 0.8161\n",
      "Epoch 3/12\n",
      "17/17 [==============================] - 42s 3s/step - loss: 0.4653 - accuracy: 0.8166 - val_loss: 0.5638 - val_accuracy: 0.8161\n",
      "Epoch 4/12\n",
      "17/17 [==============================] - 43s 2s/step - loss: 0.4321 - accuracy: 0.8301 - val_loss: 0.4046 - val_accuracy: 0.8117\n",
      "Epoch 5/12\n",
      "17/17 [==============================] - 40s 2s/step - loss: 0.3954 - accuracy: 0.8417 - val_loss: 0.3994 - val_accuracy: 0.8161\n",
      "Epoch 6/12\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.3798 - accuracy: 0.8456 - val_loss: 0.3915 - val_accuracy: 0.8341\n",
      "Epoch 7/12\n",
      "17/17 [==============================] - 34s 2s/step - loss: 0.4055 - accuracy: 0.8263 - val_loss: 0.4755 - val_accuracy: 0.8161\n",
      "Epoch 8/12\n",
      "17/17 [==============================] - 35s 2s/step - loss: 0.4339 - accuracy: 0.8359 - val_loss: 0.3824 - val_accuracy: 0.8386\n",
      "Epoch 9/12\n",
      "17/17 [==============================] - 43s 2s/step - loss: 0.3806 - accuracy: 0.8378 - val_loss: 0.3853 - val_accuracy: 0.8341\n",
      "Epoch 10/12\n",
      "17/17 [==============================] - 41s 2s/step - loss: 0.3780 - accuracy: 0.8456 - val_loss: 0.4253 - val_accuracy: 0.8296\n",
      "Epoch 11/12\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.3773 - accuracy: 0.8301 - val_loss: 0.3819 - val_accuracy: 0.8341\n",
      "Epoch 12/12\n",
      "17/17 [==============================] - 37s 2s/step - loss: 0.3459 - accuracy: 0.8629 - val_loss: 0.3973 - val_accuracy: 0.8386\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 0.3973 - accuracy: 0.8386\n",
      "Test accuracy: 0.8385650515556335\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 382, 286, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 191, 143, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 189, 141, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 94, 70, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 92, 68, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 46, 34, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 44, 32, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 22, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 20, 14, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 7, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 17920)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4587776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,124,321\n",
      "Trainable params: 5,124,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model_name = \"obstacle_detection_v3\"\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_dir = f\"checkpoint/{model_name}\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath=os.path.join(\"./checkpoint/\", \"ckpt_{epoch}\"),\n",
    "save_weights_only=True,\n",
    "save_freq=\"epoch\")\n",
    "\n",
    "#Define logger callback\n",
    "log_dir = f\"logs/{model_name}/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#Load Data\n",
    "X = np.load(\"data/train_x.npy\", allow_pickle=True)\n",
    "y = np.load(\"data/train_y_v2.npy\", allow_pickle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "#Define model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    #representing the binary classification output (obstacle or no obstacle)\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "# Train model with CSVLogger callback\n",
    "model.fit(X_train, y_train, epochs=12, batch_size=32,\n",
    "          callbacks=[checkpoint_callback, tensorboard_callback, csv_logger],\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#Save the model\n",
    "model.save(f\"{model_name}.h5\")\n",
    "weights = model.get_weights()\n",
    "np.savetxt(f\"{model_name}_weights.txt\", np.concatenate([w.flatten() for w in weights]))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the results:\n",
    "\n",
    "1. The model was trained for 10 epochs.\n",
    "2. During training, the loss decreased and the accuracy increased with each epoch.\n",
    "3. The final training accuracy was 0.9135 and the validation accuracy was 0.8895.\n",
    "4. The test accuracy of the model was 0.8895.\n",
    "5. The model architecture consists of 3 convolutional layers followed by 2 dense layers.\n",
    "6. The model has a total of 25,681,313 parameters which are all trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "File ground_truth.png: predicted class 0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "File no_obstacle.png: predicted class 0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "File side_obstacle1.png: predicted class 0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "File side_obstacle2.png: predicted class 0\n",
      "True labels: [1 0 1 1]\n",
      "Predicted labels: [0. 0. 0. 0.]\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = load_model('obstacle_detection_v3.h5')\n",
    "\n",
    "# Define the input directory and true labels\n",
    "input_dir = 'data/validate'\n",
    "true_labels = np.load('data/test_y_v2.npy')\n",
    "\n",
    "# Get a list of all image files in the directory and sort them alphabetically\n",
    "image_files = sorted([f for f in os.listdir(input_dir) if f.endswith('.png')])\n",
    "\n",
    "# Initialize empty arrays to store predicted and true labels\n",
    "predicted_labels = np.zeros(len(image_files))\n",
    "\n",
    "# Loop over each image file and make predictions\n",
    "for i, filename in enumerate(image_files):\n",
    "    # Load the image and preprocess it as needed\n",
    "    image_path = os.path.join(input_dir, filename)\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    data = np.array(image)\n",
    "    data = np.expand_dims(data, axis=0)  # shape: (1, 384, 288, 4)\n",
    "\n",
    "    # Make predictions on the image\n",
    "    predictions = model.predict(data)\n",
    "\n",
    "    # Print the predicted classes\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    print(f\"File {filename}: predicted class {predicted_class}\")\n",
    "    \n",
    "    # Store predicted label\n",
    "    predicted_labels[i] = predicted_class\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"True labels: {true_labels}\")\n",
    "print(f\"Predicted labels: {predicted_labels}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82d40570fe7a8cef5127558dff9f999d665f8f3c4074b1ee889e6c0afa23c999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
